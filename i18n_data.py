# UI Text Dictionary for potential i18n
# I18N Configuration
I18N_DATA = {
    "en": {
        "app_title": "Musubi Tuner GUI",
        "app_header": "# Musubi Tuner GUI",
        "app_desc": "A simple frontend for training LoRA models with Musubi Tuner.",
        "acc_project": "1. Project Settings",
        "desc_project": "All working files will be created under this directory.",
        "lbl_proj_dir": "Project Working Directory",
        "ph_proj_dir": "Absolute path to your project folder",
        "btn_init_project": "Initialize/Load Project",
        "acc_model": "2. Model & Dataset Configuration",
        "desc_model": "Choose the model architecture and specify the ComfyUI models directory.",
        "lbl_model_arch": "Model Architecture",
        "lbl_vram": "VRAM Size (GB)",
        "lbl_comfy_dir": "ComfyUI Models Directory",
        "ph_comfy_dir": "Absolute path to ComfyUI/models",
        "btn_validate_models": "Validate Models Directory",
        "header_dataset": "### 3. Dataset Settings",
        "desc_dataset": "Configure the resolution and batch size for the dataset. Regenerate the dataset config if you change resolution or batch size.",
        "btn_rec_res_batch": "Set Recommended Resolution & Batch Size",
        "lbl_res_w": "Resolution Width",
        "lbl_res_h": "Resolution Height",
        "lbl_batch_size": "Batch Size",
        "btn_gen_config": "Generate Dataset Config",
        "lbl_toml_preview": "TOML Preview",
        "header_control": "### Control Images (Optional)",
        "desc_control": "Use when training with control images (Flux.2/Kontext/Qwen-Image-Edit). Control images should be in a separate folder with matching filenames. For Flux.2: set no_resize_control + control_resolution (1 image: 2024x2024, multiple: 1024x1024).",
        "lbl_control_dir": "Control Images Directory",
        "ph_control_dir": "Path to control images folder",
        "lbl_control_res_w": "Control Resolution Width",
        "lbl_control_res_h": "Control Resolution Height",
        "lbl_no_resize_control": "Do Not Resize Control Images",
        "acc_preprocessing": "4. Preprocessing",
        "desc_preprocessing": "Pre-calculate latents and text encoder outputs required for training.",
        "btn_set_paths": "Set Default Paths",
        "lbl_vae_path": "VAE Path",
        "ph_vae_path": "Path to VAE model",
        "lbl_te1_path": "Text Encoder 1 Path",
        "ph_te1_path": "Path to Text Encoder 1",
        "lbl_te2_path": "Text Encoder 2 Path",
        "ph_te2_path": "Path to Text Encoder 2 (Optional)",
        "btn_cache_latents": "Cache Latents",
        "btn_cache_text": "Cache Text Encoder Outputs",
        "btn_auto_detect_paths": "Auto-detect Model Files",
        "lbl_cache_log": "Caching Log Output",
        "header_quick_actions": "### Quick Actions",
        "btn_quick_setup": "Quick Setup (Recommended)",
        "btn_check_missing": "Check Required Fields",
        "msg_quick_setup_done": "Quick setup applied.",
        "msg_missing_title": "Missing required fields:",
        "acc_training": "5. Training",
        "desc_training_basic": "Configure the training parameters. If you train with the same name again, the previous LoRA will be overwritten.",
        "desc_training_zimage": "Recommended: Use **bf16** for mixed precision. Because the base model has not been released yet, please use `z_image_de_turbo_v1_bf16.safetensors` as the base model.",
        "btn_rec_params": "Set Recommended Parameters",
        "lbl_dit_path": "Base Model / DiT Path",
        "ph_dit_path": "Path to DiT model",
        "lbl_output_name": "Output LoRA Name",
        "header_basic_params": "### Basic Parameters",
        "lbl_dim": "LoRA Rank (Dim)",
        "lbl_lr": "Learning Rate",
        "lbl_epochs": "Epochs",
        "lbl_save_every": "Save Every N Epochs",
        "accordion_advanced": "Advanced Parameters",
        "desc_training_detailed": """
### Detailed Explanation
- **Learning Rate**: Controls how much the model weights are updated during training. Lower values are safer but slower.
- **Epochs**: One complete pass through the entire training dataset.
- **Save Every N Epochs**: How often to save the model and generate sample images.
- **Discrete Flow Shift**: A parameter specific to flow matching models.
- **Block Swap**: Offloads model blocks to CPU to save VRAM. Higher values save more VRAM but slow down training. Using pinned memory can speed up Block Swap (64GB+ system RAM recommended).
- **Mixed Precision**: fp16 and bf16 are both supported; which is better depends on the model architecture. For bf16, RTX30xx or higher is required.
- **Gradient Checkpointing**: Saves VRAM by recomputing activations during backward pass.
- **FP8**: Further reduces memory usage by using 8-bit floating point arithmetic.
""",
        "lbl_flow_shift": "Discrete Flow Shift",
        "lbl_block_swap": "Block Swap (Z-Image: 0-28, Qwen: 0-58, Flux.2 4B: 0-13)",
        "lbl_use_pinned_memory_for_block_swap": "Use Pinned Memory for Block Swap",
        "lbl_mixed_precision": "Mixed Precision",
        "lbl_grad_cp": "Gradient Checkpointing",
        "lbl_fp8_scaled": "FP8 Scaled (DiT) - Enables --fp8_base and --fp8_scaled",
        "lbl_fp8_llm": "FP8 LLM/VLM (Text Encoder)",
        "header_sample_images": "### Sample Image Generation",
        "lbl_enable_sample": "Generate Sample Images During Training",
        "lbl_sample_every_n": "Generate Sample Every N Epochs",
        "lbl_sample_output_dir": "Sample Output Directory",
        "ph_sample_output_dir": "Directory to save sample images (optional, default: output_dir/sample)",
        "lbl_sample_prompt": "Sample Prompt",
        "ph_sample_prompt": "Prompt for sample generation",
        "lbl_sample_negative_prompt": "Sample Negative Prompt",
        "ph_sample_negative_prompt": "Negative prompt for sample generation",
        "lbl_sample_w": "Sample Width",
        "lbl_sample_h": "Sample Height",
        "accordion_additional": "Additional Options",
        "desc_additional_args": "Enter any additional command line arguments here. They will be appended to the training command.",
        "lbl_additional_args": "Additional Optional Arguments",
        "ph_additional_args": "--arg value --flag",
        "btn_start_training": "Start Training (New Window)",
        "acc_post_processing": "6. Post-Processing",
        "desc_post_proc": "Convert Z-Image LoRA to ComfyUI format.",
        "lbl_input_lora": "Input LoRA Path",
        "ph_input_lora": "Path to trained .safetensors file",
        "lbl_output_comfy": "Output ComfyUI LoRA Path",
        "ph_output_comfy": "Path to save converted model",
        "btn_convert": "Convert to ComfyUI Format",
        "lbl_conversion_log": "Conversion Log",
        "desc_training_flux2": "Flux.2 models use Mistral (Dev) or Qwen3 (Klein) text encoders. For training, klein-base-4b is recommended. Typical settings: LoRA dim 32, LR 1e-4. The GUI uses timestep_sampling=flux2_shift for Flux.2.",
        # New Features
        "header_presets": "### Presets",
        "lbl_preset_name": "Preset Name",
        "btn_save_preset": "Save Preset",
        "lbl_load_preset": "Load Preset",
        "btn_load_preset": "Load Selected Preset",
        "btn_refresh_presets": "Refresh Presets",
        "msg_preset_saved": "Preset saved: {name}",
        "msg_preset_loaded": "Preset loaded: {name}",
        "msg_preset_error": "Error managing presets: {e}",
        "btn_tensorboard": "Launch TensorBoard",
        "msg_tensorboard": "TensorBoard launched at http://localhost:6006",
        "lbl_resume": "Resume from Checkpoint (Optional)",
        "ph_resume": "Path to checkpoint directory (containing pytorch_model.bin or .safetensors)",
        "lbl_lr_scheduler": "LR Scheduler",
        "lbl_lr_scheduler_args": "Scheduler Args (Optional)",
        "lbl_optimizer": "Optimizer",
        "lbl_optimizer_args": "Optimizer Args (Optional)",
        "lbl_network_alpha": "Network Alpha",
        "lbl_lr_warmup_steps": "LR Warmup Steps",
        "lbl_seed": "Seed",
        "lbl_max_grad_norm": "Max Grad Norm",
        "btn_est_vram": "Estimate VRAM Usage",
        "msg_est_vram_title": "Estimated VRAM",
        "msg_est_vram_note": "Rough estimate based on resolution/batch/precision/flags. Actual usage can vary.",
        "btn_browse": "Browse",
        "msg_auto_detect_title": "Auto-detect result",
        "msg_auto_detect_found": "Found",
        "msg_auto_detect_missing": "Missing",
        "msg_auto_detect_fail": "Auto-detect failed: {e}",
        "msg_auto_detect_note_split": "Note: split weights use the first shard (e.g. 00001-of-000xx.safetensors).",
    },
    "ja": {
        "app_title": "Musubi Tuner GUI",
        "app_header": "# Musubi Tuner GUI",
        "app_desc": "Musubi TunerでLoRAモデルを学習するためのシンプルなフロントエンドです。",
        "acc_project": "1. プロジェクト設定",
        "desc_project": "すべての作業ファイルはこのディレクトリ下に作成されます。",
        "lbl_proj_dir": "プロジェクト作業ディレクトリ",
        "ph_proj_dir": "プロジェクトフォルダへの絶対パス",
        "btn_init_project": "プロジェクトを初期化/読み込み",
        "acc_model": "2. モデル＆データセット設定",
        "desc_model": "モデルアーキテクチャを選択し、ComfyUIのモデルディレクトリを指定してください。",
        "lbl_model_arch": "モデルアーキテクチャ",
        "lbl_vram": "VRAMサイズ (GB)",
        "lbl_comfy_dir": "ComfyUI モデルディレクトリ",
        "ph_comfy_dir": "ComfyUI/models への絶対パス",
        "btn_validate_models": "モデルディレクトリを検証",
        "header_dataset": "### 3. データセット設定",
        "desc_dataset": "データセットの解像度とバッチサイズを設定してください。解像度やバッチサイズを変えた場合は、データセット設定を再生成してください。",
        "btn_rec_res_batch": "推奨解像度とバッチサイズを設定",
        "lbl_res_w": "解像度 幅",
        "lbl_res_h": "解像度 高さ",
        "lbl_batch_size": "バッチサイズ",
        "btn_gen_config": "データセット設定(TOML)を生成",
        "lbl_toml_preview": "TOML プレビュー",
        "header_control": "### 制御画像 (オプション)",
        "desc_control": "制御画像を使う学習向け（Flux.2 / Kontext / Qwen-Image-Edit）。制御画像は同名ファイルで別フォルダに置きます。Flux.2は no_resize_control と control_resolution を指定（1枚: 2024x2024 / 複数: 1024x1024）。",
        "lbl_control_dir": "制御画像フォルダ",
        "ph_control_dir": "制御画像フォルダのパス",
        "lbl_control_res_w": "制御画像 解像度(幅)",
        "lbl_control_res_h": "制御画像 解像度(高さ)",
        "lbl_no_resize_control": "制御画像をリサイズしない",
        "acc_preprocessing": "4. 前処理 (Preprocessing)",
        "desc_preprocessing": "学習に必要となるLatentsとテキストエンコーダーの出力を事前計算します。",
        "btn_set_paths": "デフォルトパスを設定",
        "lbl_vae_path": "VAE パス",
        "ph_vae_path": "VAEモデルへのパス",
        "lbl_te1_path": "テキストエンコーダー1 パス",
        "ph_te1_path": "テキストエンコーダー1へのパス",
        "lbl_te2_path": "テキストエンコーダー2 パス",
        "ph_te2_path": "テキストエンコーダー2へのパス (オプション)",
        "btn_cache_latents": "Latentsをキャッシュ",
        "btn_cache_text": "テキストエンコーダー出力をキャッシュ",
        "btn_auto_detect_paths": "モデルファイルを自動検出",
        "lbl_cache_log": "キャッシュログ出力",
        "header_quick_actions": "### クイック操作",
        "btn_quick_setup": "クイック設定 (推奨)",
        "btn_check_missing": "必須項目チェック",
        "msg_quick_setup_done": "クイック設定を適用しました。",
        "msg_missing_title": "未入力の必須項目:",
        "acc_training": "5. 学習 (Training)",
        "desc_training_basic": "学習パラメータを設定してください。学習後、同じ名前で学習すると前のLoRAが上書きされます。",
        "desc_training_zimage": "推奨: 混合精度には **bf16** を使用してください。Baseモデルがリリースされていないため、ostris氏の `z_image_de_turbo_v1_bf16.safetensors` を使用してください。",
        "btn_rec_params": "推奨パラメータを設定",
        "lbl_dit_path": "ベースモデル / DiT パス",
        "ph_dit_path": "DiTモデルへのパス",
        "lbl_output_name": "出力 LoRA 名",
        "header_basic_params": "### 基本パラメータ",
        "lbl_dim": "LoRAランク (Dim)",
        "lbl_lr": "学習率 (Learning Rate)",
        "lbl_epochs": "エポック数 (Epochs)",
        "lbl_save_every": "Nエポックごとに保存",
        "accordion_advanced": "詳細パラメータ",
        "desc_training_detailed": """
### 詳細説明
- **学習率 (Learning Rate)**: 学習中にモデルの重みをどれくらい更新するかを制御します。低い値の方が安全ですが、学習が遅くなります。
- **エポック数 (Epochs)**: 学習データセット全体を通す回数です。
- **保存頻度 (Save Every N Epochs)**: モデルの保存とサンプル生成を行う頻度です。
- **Discrete Flow Shift**: Flow Matchingモデル特有のパラメータです。
- **Block Swap**: VRAMを節約するためにモデルブロックをCPUにオフロードします。値を大きくするとVRAMを節約できますが、学習が遅くなります。共有メモリを使うとBlock Swapが高速化されます（64GB以上のメインRAMを推奨）。
- **混合精度 (Mixed Precision)**: モデルアーキテクチャによりfp16とbf16のどちらが適しているかは異なります。bf16はRTX30xx以降のGPUが必要です。
- **Gradient Checkpointing**: Backwardパス中にアクティベーションを再計算することでVRAMを節約します。
- **FP8**: 8ビット浮動小数点演算を使用することでメモリ使用量をさらに削減します。
""",
        "lbl_flow_shift": "Discrete Flow Shift",
        "lbl_block_swap": "Block Swap (Z-Image: 0-28, Qwen: 0-58)",
        "lbl_use_pinned_memory_for_block_swap": "Block Swapに共有メモリを使う",
        "lbl_mixed_precision": "混合精度 (Mixed Precision)",
        "lbl_grad_cp": "Gradient Checkpointing",
        "lbl_fp8_scaled": "FP8 Scaled (DiT) - --fp8_base と --fp8_scaled を有効化",
        "lbl_fp8_llm": "FP8 LLM/VLM (テキストエンコーダー)",
        "header_sample_images": "### サンプル画像生成",
        "lbl_enable_sample": "学習中にサンプル画像を生成する",
        "lbl_sample_every_n": "Nエポックごとにサンプルを生成",
        "lbl_sample_output_dir": "サンプル出力先フォルダ",
        "ph_sample_output_dir": "サンプル画像の出力先 (省略時は output_dir/sample)",
        "lbl_sample_prompt": "サンプル画像プロンプト",
        "ph_sample_prompt": "サンプル生成用のプロンプト",
        "lbl_sample_negative_prompt": "サンプル画像ネガティブプロンプト",
        "ph_sample_negative_prompt": "サンプル生成用のネガティブプロンプト",
        "lbl_sample_w": "サンプル画像 幅",
        "lbl_sample_h": "サンプル画像 高さ",
        "accordion_additional": "追加オプション",
        "desc_additional_args": "追加のコマンドライン引数を入力してください。これらは学習コマンドに追加されます。",
        "lbl_additional_args": "追加のオプション引数",
        "ph_additional_args": "--arg value --flag",
        "btn_start_training": "学習を開始 (新しいウィンドウが開きます)",
        "acc_post_processing": "6. 後処理 (Post-Processing)",
        "desc_post_proc": "Z-Image LoRAをComfyUI形式に変換します。",
        "lbl_input_lora": "入力 LoRA パス",
        "ph_input_lora": "学習済み .safetensors ファイルへのパス",
        "lbl_output_comfy": "出力 ComfyUI LoRA パス",
        "ph_output_comfy": "変換後のモデルの保存先パス",
        "btn_convert": "ComfyUI形式に変換",
        "lbl_conversion_log": "変換ログ",
        "desc_qwen_notes": "Qwen-Image 特有の注意点。",
        "desc_training_flux2": "Flux.2はMistral (Dev) または Qwen3 (Klein) のテキストエンコーダーを使用します。学習は klein-base-4b 推奨。目安: LoRA dim 32 / LR 1e-4。GUIは Flux.2 に timestep_sampling=flux2_shift を使用します。",
        # New Features
        "header_presets": "### プリセット設定",
        "lbl_preset_name": "プリセット名",
        "btn_save_preset": "プリセットを保存",
        "lbl_load_preset": "プリセットを選択",
        "btn_load_preset": "プリセットを読み込む",
        "btn_refresh_presets": "更新",
        "msg_preset_saved": "プリセットを保存しました: {name}",
        "msg_preset_loaded": "プリセットを読み込みました: {name}",
        "msg_preset_error": "プリセットエラー: {e}",
        "btn_tensorboard": "TensorBoardを起動 (学習グラフ)",
        "msg_tensorboard": "TensorBoardを起動しました: http://localhost:6006",
        "lbl_resume": "学習を再開する (Resume)",
        "ph_resume": "チェックポイントディレクトリへのパス (pytorch_model.bin/.safetensors を含むフォルダ)",
        "lbl_lr_scheduler": "学習率スケジューラ",
        "lbl_lr_scheduler_args": "スケジューラ引数 (オプション)",
        "lbl_optimizer": "オプティマイザ",
        "lbl_optimizer_args": "オプティマイザ引数 (オプション)",
        "lbl_network_alpha": "ネットワークアルファ",
        "lbl_lr_warmup_steps": "ウォームアップステップ",
        "lbl_seed": "シード値",
        "lbl_max_grad_norm": "勾配クリップ上限",
        "btn_est_vram": "VRAM使用量を見積もる",
        "msg_est_vram_title": "VRAM目安",
        "msg_est_vram_note": "解像度/バッチ/精度/各種フラグからの概算です。実際は変動します。",
        "btn_browse": "参照",
        "msg_auto_detect_title": "自動検出結果",
        "msg_auto_detect_found": "見つかった項目",
        "msg_auto_detect_missing": "見つからない項目",
        "msg_auto_detect_fail": "自動検出に失敗しました: {e}",
        "msg_auto_detect_note_split": "注: 分割重みは最初のファイル（例: 00001-of-000xx.safetensors）を指定します。",
    },
}
